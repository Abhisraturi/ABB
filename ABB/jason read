import snap7
import pandas as pd
import json
import time
import re
from datetime import datetime
from collections import defaultdict
from snap7.util import get_bool, get_int, get_real, get_dint, get_byte
from snap7.types import Areas

def connect_to_plc(ip, rack, slot):
    client = snap7.client.Client()
    client.connect(ip, rack, slot)
    if client.get_connected():
        print(f"Connected to PLC at {ip}")
    else:
        raise Exception("Connection to PLC failed.")
    return client

def parse_tag(tag_type, address):
    tag_type = tag_type.strip().upper()
    address = address.strip().upper()

    if address.startswith("DB"):
        db_match = re.match(r"DB\s*(\d+)\.DB([XBWLD])\s*(\d+)(?:\.(\d))?", address)
        if not db_match:
            raise ValueError(f"Invalid DB address format: {address}")
        db_number = int(db_match.group(1))
        byte = int(db_match.group(3))
        bit = int(db_match.group(4)) if db_match.group(4) else None
        return Areas.DB, db_number, byte, bit, tag_type

    elif address.startswith("I") or address.startswith("Q") or address.startswith("M"):
        io_match = re.match(r"([IQM])\s*(\d+)(?:\.(\d))?", address)
        if not io_match:
            raise ValueError(f"Invalid I/Q/M address format: {address}")
        area = {"I": Areas.PE, "Q": Areas.PA, "M": Areas.MK}[io_match.group(1)]
        byte = int(io_match.group(2))
        bit = int(io_match.group(3)) if io_match.group(3) else None
        return area, 0, byte, bit, tag_type

    elif address.startswith("MD"):
        byte = int(address.replace("MD", "").strip())
        return Areas.MK, 0, byte, None, tag_type

    else:
        raise ValueError(f"Unsupported address format: {address}")

def get_read_length(tag_type):
    if tag_type in ["REAL", "DINT"]:
        return 4
    elif tag_type == "INT":
        return 2
    else:
        return 1

def load_and_group_tags(csv_path):
    df = pd.read_csv(csv_path)
    if 'Type' not in df.columns or 'Address' not in df.columns:
        raise Exception("CSV must contain 'Type' and 'Address' columns")

    grouped = defaultdict(list)

    for _, row in df.iterrows():
        try:
            area, db, byte, bit, parsed_type = parse_tag(row['Type'], row['Address'])
            grouped[(area, db)].append((byte, bit, parsed_type, row['Address']))
        except Exception as e:
            print(f"Skipping tag {row['Address']} due to error: {e}")

    return grouped

def read_grouped_tags(client, grouped_tags):
    start_time = time.time()
    all_data = {}

    for (area, db), tag_list in grouped_tags.items():
        if not tag_list:
            continue

        min_byte = min(byte for byte, _, _, _ in tag_list)
        max_byte = max(byte + get_read_length(tp) for byte, _, tp, _ in tag_list)
        length = max_byte - min_byte

        try:
            data = client.read_area(area, db, min_byte, length)
        except Exception as e:
            print(f"Failed to read area={area} db={db}: {e}")
            for _, _, _, address in tag_list:
                all_data[address] = f"Read error: {e}"
            continue

        for byte, bit, tag_type, address in tag_list:
            offset = byte - min_byte
            try:
                if tag_type == "BOOL":
                    if bit is None:
                        raise ValueError("Missing bit index in BOOL tag")
                    value = get_bool(data, offset, bit)
                elif tag_type == "INT":
                    value = get_int(data, offset)
                elif tag_type == "REAL":
                    value = get_real(data, offset)
                elif tag_type == "DINT":
                    value = get_dint(data, offset)
                elif tag_type == "BYTE":
                    value = get_byte(data, offset)
                else:
                    value = f"Unsupported: {tag_type}"
                all_data[address] = value
            except Exception as ve:
                print(f"Parse error for {address}: {ve}")
                all_data[address] = f"Parse error: {ve}"

    timestamp = datetime.now().strftime("%Y-%m-%d_%H-%M-%S")
    json_filename = f"plc_data_{timestamp}.json"
    with open(json_filename, "w") as f:
        json.dump(all_data, f, indent=4)

    end_time = time.time()
    print(f"\nTotal read time: {end_time - start_time:.4f} seconds")
    print(f"Data saved to {json_filename}\n")

def main():
    ip = "172.16.12.40"
    rack = 0
    slot = 5
    csv_file = "tags.csv"

    client = connect_to_plc(ip, rack, slot)
    grouped_tags = load_and_group_tags(csv_file)

    try:
        while True:
            read_grouped_tags(client, grouped_tags)
            time.sleep(1)
    except KeyboardInterrupt:
        print("Stopped by user.")
    finally:
        client.disconnect()
        print("Disconnected from PLC.")

if __name__ == "__main__":
    main()
